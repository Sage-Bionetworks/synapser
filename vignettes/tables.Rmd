---
title: "Tables"
author: "Bruce Hoff"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tables}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
## Tables
Synapse Tables enable storage of tabular data in Synapse in a form that can be queried using a SQL-like query language.

A table has a Schema and holds a set of rows conforming to that schema.

A Schema defines a series of Column of the following types: STRING, DOUBLE, INTEGER, BOOLEAN, DATE, ENTITYID, FILEHANDLEID, LINK, LARGETEXT, USERID

Preliminaries:
```{r collapse=TRUE}
library(synapser)
synLogin()
# Create a new project
projectName<-sprintf("My unique project created on %s", format(Sys.time(), "%a %b %d %H%M%OS4 %Y"))
project<-Project(projectName)
project<-synStore(project)

```
To create a Table, you first need to create a Table Schema. This defines the columns of the table:
```{r collapse=TRUE}
cols <- list(
    Column(name='Name', columnType='STRING', maximumSize=20),
    Column(name='Chromosome', columnType='STRING', maximumSize=20),
    Column(name='Start', columnType='INTEGER'),
    Column(name='End', columnType='INTEGER'),
    Column(name='Strand', columnType='STRING', enumValues=list('+', '-'), maximumSize=1),
    Column(name='TranscriptionFactor', columnType='BOOLEAN'))

schema <- Schema(name='My Favorite Genes', columns=cols, parent=project)
```
Next, let’s load some data. Let’s say we had a file, genes.csv:

```{r collapse=TRUE}
genes<-data.frame(
	Name=c("foo", "arg", "zap", "bah", "bnk", "xyz"), 
	Chromosome=c(1,2,2,1,1,1), 
	Start=c(12345,20001,30033,40444,51234,61234),
	End=c(126000,20200,30999,41444,54567,68686),
	Strand=c('+', '+', '-', '-', '+', '+'),
	TranscriptionFactor=c(F,F,F,F,T,F))
genesFile<-tempfile()
write.csv(genes, file=genesFile, row.names=FALSE)
```

Let’s store that in Synapse:
```{r collapse=TRUE}
table<-Table(schema, genesFile)
table<-synStore(table)
tableId<-table$schema$properties$id
```

The Table() function takes two arguments, a schema object and data in some form, which can be:

* a path to a CSV file
* a data frame
* a RowSet object
* a list of lists where each of the inner lists is a row

We now have a table populated with data. Let’s try to query:

```{r collapse=TRUE}
results <- synTableQuery(sprintf("select * from %s where Chromosome='1' and Start < 41000 and End > 20000", tableId))
results$asDataFrame()
```

## Changing Data

Once the schema is settled, changes come in two flavors: appending new rows and updating existing ones.

Appending new rows is fairly straightforward. To continue the previous example, we might add some new genes:
```{r collapse=TRUE}
moreGenes<-data.frame(
	Name=c("abc", "def"), 
	Chromosome=c(2,2), 
	Start=c(12345,20001),
	End=c(126000,20200),
	Strand=c('+', '+'),
	TranscriptionFactor=c(F,F))
moreGenesFile<-tempfile()
write.csv(moreGenes, file=moreGenesFile, row.names=FALSE)
synStore(Table(tableId, moreGenesFile))
```

Updating rows requires an etag, which identifies the most recent change set plus row IDs and version numbers for each row to be modified. We get those by querying before updating. Minimizing changesets to contain only rows that actually change will make processing faster.

For example, let’s update the names of some of our favorite genes:
```{r collapse=TRUE}
results <- synTableQuery(sprintf("select * from %s where Chromosome='1'", tableId))
df <-results$asDataFrame(rowIdAndVersionInIndex=FALSE)
df['Name'] = c('rzing', 'zing1', 'zing2', 'zing3')
write.csv(df, results$filepath, row.names=FALSE)
```

Let’s save that:
```{r collapse=TRUE}
table<-Table(tableId, results$filepath)
table<-synStore(table)
```

Now, query the table again to see your changes:
```{r collapse=TRUE}
results <- synTableQuery(sprintf("select * from %s limit 10", tableId))
results$asDataFrame()
```
The etag is used by the server to prevent concurrent users from making conflicting changes, a technique called optimistic concurrency. In case of a conflict, your update may be rejected. You then have to do another query an try your update again.

## Changing Table Structure

Adding columns can be done using the methods Schema$addColumn() or addColumns() on the Schema object:
```{r collapse=TRUE}
schema <- synGet(tableId)
newColumn <- synStore(Column(name='Test', columnType='BOOLEAN'))
schema$addColumn(newColumn)
schema <- synStore(schema)
```
Renaming or otherwise modifying a column involves removing the column and adding a new column:
```{r collapse=TRUE}
schema$removeColumn(newColumn)
testColumn <- synStore(Column(name='IsTest', columnType='BOOLEAN'))
schema$addColumn(testColumn)
schema <- synStore(schema)
```
Now we can set the values for the new column:
```{r collapse=TRUE}
results <- synTableQuery(sprintf("SELECT * FROM %s", tableId))
data <- results$asDataFrame(rowIdAndVersionInIndex=FALSE)
data['IsTest'] = c(T,F,T,T,T,F,F,T)
write.csv(data, results$filepath, row.names=FALSE)
synStore(Table(tableId, results$filepath))
```


## Updating Column Type

Column 'IsTest' has type BOOLEAN. We cannot add a new row with 'IsTest' as 'NA' since 'NA' is not a valid value for type BOOLEAN. Let's change the ColumnType to 'STRING':
```{r collapse=TRUE}
# getting the existing table metadata and data
originalSchema <- synGet(tableId)
oldQueryResults <- synTableQuery(sprintf("SELECT * FROM %s", tableId))
oldData <- oldQueryResults$asDataFrame(rowIdAndVersionInIndex=FALSE)

# remove the column
originalSchema$removeColumn(testColumn)
newSchema <- synStore(originalSchema)

# create a new Column
newCol <- Column(name='IsTest', columnType='STRING', maximumSize=5)
newCol <- synStore(newCol)

# add the new column to the new table
newSchema$addColumn(newCol)
newSchema <- synStore(newSchema)

# copy the data over to the new column
newQueryResults <- synTableQuery(sprintf("SELECT * FROM %s", newSchema$properties$id))
newData <- newQueryResults$asDataFrame(rowIdAndVersionInIndex=FALSE)
newData['IsTest'] <- oldData['IsTest']

# save the change
write.csv(newData, newQueryResults$filepath, row.names=FALSE)
synStore(Table(tableId, newQueryResults$filepath))

# add the new data
moreGenes<-data.frame(
    Name=c("not_sure"), 
    Chromosome=c(2), 
    Start=c(12345),
    End=c(126000),
    Strand=c('+'),
    TranscriptionFactor=c(F),
    IsTest=c('NA'))
moreGenesFile<-tempfile()
write.csv(moreGenes, file=moreGenesFile, row.names=FALSE)
synStore(Table(tableId, moreGenesFile))
```

## Table Attached Files

Synapse tables support a special column type called ‘File’ which contain a file handle, an identifier of a file stored in Synapse. Here’s an example of how to upload files into Synapse, associate them with a table and read them back later:

```{r collapse=TRUE, eval=F}
# example depends on synapseclient.uploadSynapseManagedFileHandle()
# and not available until python client 1.7.3 is released
newCols <- list(
    Column(name='artist', columnType='STRING', maximumSize=50),
    Column(name='album', columnType='STRING', maximumSize=50),
    Column(name='year', columnType='INTEGER'),
    Column(name='catalog', columnType='STRING', maximumSize=50),
    Column(name='cover', columnType='FILEHANDLEID'))
newSchema <- synStore(Schema(name='Jazz Albums', columns=newCols, parent=project))

newData <- data.frame(
  artist = c("John Coltrane", "Sonny Rollins", "Sonny Rollins", "Kenny Burrel"),
  album = c("Blue Train", "Vol. 2", "Newk's Time", "Kenny Burrel"),
  year = c(1957, 1957, 1958, 1956),
  catalog = c("BLP 1577", "BLP 1558", "BLP 4001", "BLP 1543")
)

# writing some temp files to upload or pointing to existing files in your system

files <- c("coltraneBlueTrain.jpg", "rollinsBN1558.jpg", "rollinsBN4001.jpg", "burrellWarholBN1543.jpg")

# upload to filehandle service
files <- lapply(files, function (f) {
  temp_file <- tempfile(f)
  write(f, file=temp_file)
  synUploadSynapseManagedFileHandle(f)
  })
# get the filehandle ids
fileHandleIds <- sapply(files, function(f) f[1]$id)
newData["covers"] <- fileHandleIds

tempFile<-tempfile()
write.csv(newData, file=tempFile, row.names=FALSE)
synStore(Table(newSchema$properties$id, tempFile))
```

## Set Annotations
A table is a Synapse entity. Annotations on table works the same way with annotations on any other entity types. Please visit [synapser vignettes](synapser.html#annotating-synapse-entities) to read more about how to set annotations on an entity.

## Deleting Rows
Query for the rows you want to delete and call syn.delete on the results:
```{r collapse=TRUE}
results <- synTableQuery(sprintf("select * from %s where Chromosome='2'", tableId))
deleted <- synDelete(results$asRowSet())
```

## Deleting Table
Deleting the schema deletes the whole table and all rows:
```{r collapse=TRUE}
synDelete(schema)
```

## Queries
The query language is quite similar to SQL select statements, except that joins are not supported. The documentation for the Synapse API has lots of [query examples](http://docs.synapse.org/rest/org/sagebionetworks/repo/web/controller/TableExamples.html).

For more details see the native reference documentation, e.g.:

```{r eval=F}
?Schema
?Column
?Row
?Table
```

```{r collapse=TRUE}
synDelete(project)
```
